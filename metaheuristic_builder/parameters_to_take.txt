When creating a metaheuristic it is important to not use markdown code blocks such as  ```python or ```, it is important to not invent any parameter or operator, only use the ones that will be provided below after these operators and selectors explanations.,
These are the following explanations:
- "random_search" operator: Is an algorithm that is useful for ill-structured global optimization problems, where the objective function may be nonconvex, nondifferentiable, and possibly discontinuous over a continuous, discrete, or mixed continuous-discrete domain.
- "central_force_dynamic" operator: Is an algorithm that performs multidimensional search and has roots with gravitation kinematics, it is a deterministic algorithm that provides significant advantage. 
- "differential_mutation" operator: Is an algorithm that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. Can search very large spaces of candidate solutions, however does not guarantee an optimal solution is ever found. 
- "firefly_dynamic" operator: Is an algorithm that uses real random numbers. It is based on the global communication among the swarming particles. It appears to be more effective in multiobjective optimization. There are different types of areas where firefly algorithms are applied. It is used in different types of areas are optimization problem, benchmark problem, Networking problems, and Image Processing problems.
- "genetic_crossover" operator: Is an algorithm used to combine the genetic information of two parents to generate new offspring. It is one way to stochastically generate new solutions from an existing population, and is analogous to the crossover that happens during sexual reproduction in biology. When deciding to use this operator (genetic_crossover) the "genetic_mutation" operator must be used to. 
- "genetic_mutation" operator: Is an algorithm that involves generating a random variable for each bit in a sequence. This random variable tells whether or not a particular bit will be flipped. This mutation procedure, based on the biological point mutation, is called single point mutation. Other types of mutation operators are commonly used for representations other than binary, such as floating-point encodings or representations for combinatorial problems. Its' purpose is to introduce diversity into the sampled population. Mutation operators are used in an attempt to avoid local minima by preventing the population of chromosomes from becoming too similar to each other, thus slowing or even stopping convergence to the global optimum. When deciding to use this operator (genetic_mutation) the "genetic_crossover" operator must be used to. 
- "gravitational_search" operator: Is an algorithm that could be considered as an isolated system of masses. It is like a small artificial world of masses obeying the Newtonian laws of gravitation and motion. Tends to find the global optimum faster than other algorithms and hence has a higher convergence rate.
- "random_flight" operator:  Is an algorithm that uses random jumps across the search space, typically controlled by a scale factor and a distribution (e.g., Levy, uniform, or Gaussian). This allows the algorithm to explore new regions more aggressively, making it suitable for escaping local minima and searching widely for global optima.
- "local_random_walk" operator: Is an algorithm that performs small, random steps in the vicinity of the current solution. It uses a probability factor and a distribution (e.g., uniform, Gaussian, or Levy) to determine the size and direction of each step. This operator is beneficial for local exploration and refinement around promising regions. 
- "random_sample" operator: Is an algorithm that samples solutions randomly from the entire search space. Itâ€™s often used for unbiased exploration and can act as a baseline search method. Since it lacks directional guidance, it covers a broad range but relies on volume to achieve diversity in solutions.
- "spiral_dynamic" operator:  Is an algorithm that uses a spiraling pattern to move towards the search target, controlled by parameters like radius, angle, and sigma. This dynamic is inspired by natural spirals and can help converge toward optima by progressively tightening the search pattern around a promising region.
- "swarm_dynamic" operator: Is an algorithm that models collective behavior, where individual agents (solutions) share information and are influenced by both their own best positions and the best position of the entire swarm. Parameters such as self_conf (self-confidence), swarm_conf (swarm confidence), and distribution (e.g., uniform, Gaussian, or Levy) govern how agents move and interact, making this operator effective for balancing exploration and exploitation in complex landscapes.

When creating the metaheuristics use at the first iteration only one search operator, and as the iterations keep increasing, you can add more and more operators. 
Also, remember to write the operators' names, virables' names and selectors' names exactly as shown down below. For example, the operators' names are ALL ALWAYS written in lower case and with a '_' instead of a space between words.
So write the parameters' exactly as shown down below. 
These are the parameters to take, (REMEMBER that each operaotr must have its own selector, and that depending on the selected operator, YOU MUST ONLY USE USE ONE VARIABLE PER PARAMETER, DO NOT USE THE WHOLE ARRAY, and write the variable without an array format, but as a float or string format):
{
  "random_search": {  # operator
    { # parameters
      "scale": 1.0 or 0.01,
      "distribution": "uniform" or "gaussian" or "levy"
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "central_force_dynamic": {  # operator
    { # parameters
      "gravity": 0.001,
      "alpha": 0.01,
      "beta": 1.5,
      "dt": 1.0
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "differential_mutation": { # operator
    { # parameters
      "expression": "rand" or "best" or "current" or  "current-to-best" or "rand-to-best" or "rand-to-best-and-current",
      "num_rands": 1,
      "factor": 1.0
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "firefly_dynamic": { # operator
    { # parameters
      "distribution": "uniform" or "gaussian" or "levy",
      "alpha": 1.0,
      "beta": 1.0,
      "gamma": 100.0
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "genetic_crossover": { # operator: - If you decide to use the operator genetic_crossover, then you must use genetic_mutation too. And vice versa. 
    { # parameters
      "pairing": "rank" or "cost" or "random" or"tournament_2_100",
      "crossover": "single" or "two" or "uniform" or "blend" or "linear_0.5_0.5",
      "mating_pool_factor": 0.4
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "genetic_mutation": { # operator: - If you decide to use the operator genetic_crossover, then you must use genetic_mutation too. And vice versa. 
    { # parameters
      "scale": 1.0,
      "elite_rate": 0.1,
      "mutation_rate": 0.25,
      "distribution": "uniform" or "gaussian" or "levy"
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "gravitational_search": { # operator
    { # parameters
      "gravity": 1.0,
      "alpha": 0.02
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "random_flight": { # operator
    { # parameters
      "scale": 1.0,
      "distribution": "levy" or "uniform" or"gaussian",
      "beta": 1.5
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "local_random_walk": { # operator
    { # parameters
      "probability": 0.75,
      "scale": 1.0,
      "distribution": "uniform" or "gaussian" or "levy"
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "random_sample": { # operator
    { # parameters }
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "spiral_dynamic": { # operator
    { # parameters
      "radius": 0.9,
      "angle": 22.5,
      "sigma": 0.1
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  },
  "swarm_dynamic": { # operator
   { # parameters
      "factor": 0.7 or 1.0,
      "self_conf": 2.54,
      "swarm_conf": 2.56,
      "version": "inertial" or "constriction",
      "distribution": "uniform" or "gaussian" or "levy"
    },
    selector: "greedy" or "all" or"metropolis" or"probabilistic"
  }
}

When creating a metaheuristic take into account: You should NOT use any markdown code or use the triple backticks  (```) anywhere in your response, 
all outputs must be plain text. Use only the benchmark_function and its' dimension provided. 
 
Format your response exaclty as follows: 
      
# Name: [Your chosen name for the metaheuristic]
# Code:
import sys
from pathlib import Path

project_dir = Path(__file__).resolve().parents[2] # Remember to write well this line: 'project_dir = Path(__file__).resolve().parents[2]'
sys.path.insert(0, str(project_dir))
import benchmark_func as bf
import metaheuristic as mh

fun = bf.{self.benchmark_function}({self.dimensions}) # This is the selected problem, the problem may vary depending on the case.
prob = fun.get_formatted_problem()

heur = [
    (  # Search operator 1
        '[operator_name]',
        {
            'parameter1': value1,
            'parameter2': value2,
            more parameters as needed
        },
        '[selector_name]'
    ),
    (
        '[operator_name]',
        {
            'parameter1': value1,
            'parameter2': value2,
            ... more parameters as needed
        },
        '[selector_name]'
    )
]

met = mh.Metaheuristic(prob, heur, num_iterations=100)
met.verbose = True
met.run()

print('x_best = {}, f_best = {}'.format(*met.get_solution()))

# Short explanation and justification:
# [Your explanation here, each line starting with '#']
 