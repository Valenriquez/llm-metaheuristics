{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "#### chromadb:\n",
    "#### ollama:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chroma_client.delete_collection(name=\"feedback_collection\") # Delete a collection and all associated embeddings, documents, and metadata. ⚠️ This is destructive and not reversible\n",
    "#chroma_client.delete_collection(name=\"python_collection\") # Delete a collection and all associated embeddings, documents, and metadata. ⚠️ This is destructive and not reversible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Feedback Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_collection = chroma_client.create_collection(name=\"feedback_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys/ollama_output_Rastrigin(5)_20241121_000015/execution_optuna_result_0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Construct the file path\u001b[39;00m\n\u001b[1;32m     10\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, folder_name, file_name)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     12\u001b[0m     code_file \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(metaheuristic_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys/ollama_output_Rastrigin(5)_20241121_000015/execution_optuna_result_0.txt'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "base_path = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys\"\n",
    "folder_name = \"ollama_output_Rastrigin(5)_20241121_000015\"\n",
    "file_name = \"execution_optuna_result_0.txt\"\n",
    "metaheuristic_file  = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys/ollama_output_Rastrigin(5)_20241121_000015/execution_iteration_0.py\"\n",
    "\n",
    "# Construct the file path\n",
    "file_path = os.path.join(base_path, folder_name, file_name)\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    code_file = file.read()\n",
    "\n",
    "\n",
    "with open(metaheuristic_file, 'r', encoding='utf-8') as file:\n",
    "    metaheuristic_code_file = file.read()\n",
    "\n",
    "hyperparameters_pattern = r\"Mejores hiperparámetros encontrados:\\n({.*?})\"\n",
    "performance_pattern = r\"Mejor rendimiento encontrado:\\n([\\d.]+)\"\n",
    "\n",
    "hyperparameters_match = re.search(hyperparameters_pattern, code_file, re.DOTALL)\n",
    "hyperparameters_dict = eval(hyperparameters_match.group(1)) if hyperparameters_match else None\n",
    "\n",
    "performance_match = re.search(performance_pattern, code_file)\n",
    "performance_found = float(performance_match.group(1)) if performance_match else None\n",
    "\n",
    "if hyperparameters_dict:\n",
    "    radius = float(hyperparameters_dict.get('radius', 0))\n",
    "    angle = float(hyperparameters_dict.get('angle', 0))\n",
    "    sigma = float(hyperparameters_dict.get('sigma', 0))\n",
    "    factor = float(hyperparameters_dict.get('factor', 0))\n",
    "    self_conf = float(hyperparameters_dict.get('self_conf', 0))\n",
    "    swarm_conf = float(hyperparameters_dict.get('swarm_conf', 0))\n",
    "    version = hyperparameters_dict.get('version', '')\n",
    "    distribution = hyperparameters_dict.get('distribution', '')\n",
    "\n",
    "    \n",
    "    print(f\"radius: {radius}\")\n",
    "    print(f\"angle: {angle}\")\n",
    "    print(f\"sigma: {sigma}\")\n",
    "    print(f\"factor: {factor}\")\n",
    "    print(f\"self_conf: {self_conf}\")\n",
    "    print(f\"swarm_conf: {swarm_conf}\")\n",
    "    print(f\"version: {version}\")\n",
    "    print(f\"distribution: {distribution}\")\n",
    "\n",
    "print(f\"Performance found: {performance_found}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius\": 0.5405117232957318,\"angle\": 14.408693167938573,\"sigma\": 0.046498549162240936,\"factor\": 0.11779253652571474,\"self_conf\": 2.951026835950703,\"swarm_conf\": 2.7883600653077947,\"version\": inertial,\"distribution\": uniform, \"performance_found\": 7.955976169162414\n"
     ]
    }
   ],
   "source": [
    "number_iteration = \"id_0\"\n",
    "parameters  = f\"\"\"radius\": {radius},\"angle\": {angle},\"sigma\": {sigma},\"factor\": {factor},\"self_conf\": {self_conf},\"swarm_conf\": {swarm_conf},\"version\": {version},\"distribution\": {distribution}, \"performance_found\": {performance_found}\"\"\"\n",
    "print(parameters)\n",
    "feedback_collection.add(\n",
    "    documents=[metaheuristic_code_file, parameters],\n",
    "    metadatas=[{'source': 'metaheuristic_code_file'}, {'source': 'parameters'}],\n",
    "    ids=[\"id_0\", \"id_1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_collection.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radius\": 0.5405117232957318,\"angle\": 14.408693167938573,\"sigma\": 0.046498549162240936,\"factor\": 0.11779253652571474,\"self_conf\": 2.951026835950703,\"swarm_conf\": 2.7883600653077947,\"version\": inertial,\"distribution\": uniform, \"performance_found\": 7.955976169162414\n"
     ]
    }
   ],
   "source": [
    "# all-minilm:latest\n",
    "output = ollama.embeddings(\n",
    "        prompt=\"give me all parameters\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results = feedback_collection.query (\n",
    "        query_embeddings=[output[\"embedding\"]],\n",
    "        n_results=1\n",
    ")\n",
    "data = results['documents'][0][0]\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Metaheuristic Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_collection = chroma_client.create_collection(name=\"python_collection\")\n",
    "# /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/operators_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added metaheuristic_template.txt to the collection\n",
      "Added optuna_template.txt to the collection\n",
      "Added operators.txt to the collection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ollama  # Replace with the actual library you use for embeddings\n",
    "\n",
    "# Define the directory containing Python files\n",
    "python_files_directory = '/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/metaheuristic_builder'\n",
    "\n",
    "# Iterate through all items in the directory\n",
    "for d in os.listdir(python_files_directory):\n",
    "    file_path = os.path.join(python_files_directory, d)  # Full path to the file\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        try:\n",
    "            # Open and read the file\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            # Generate embeddings for the file content\n",
    "            response = ollama.embeddings(model=\"all-minilm:latest\", prompt=file_content)\n",
    "            embedding = response.get(\"embedding\")\n",
    "\n",
    "            # Add embedding to the collection if valid\n",
    "            if embedding:\n",
    "                python_collection.add(\n",
    "                    ids=[d],\n",
    "                    embeddings=[embedding],\n",
    "                    documents=[file_content],\n",
    "                    metadatas=[{\"filename\": d}]\n",
    "                )\n",
    "                print(f\"Added {d} to the collection\")\n",
    "            else:\n",
    "                print(f\"Warning: Empty embedding generated for {d}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {d}: {e}\")\n",
    "    else:\n",
    "        # Skip if it's not a file\n",
    "        print(f\"Skipping {d}, not a file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_collection.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Operators Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators_collection = chroma_client.create_collection(name=\"operators_collection\")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added firefly_dynamic.txt to the collection\n",
      "Added differential_mutation.txt to the collection\n",
      "Added random_sample.txt to the collection\n",
      "Added gravitational_search.txt to the collection\n",
      "Added central_force_dynamic.txt to the collection\n",
      "Added genetic_crossover.txt to the collection\n",
      "Added random_search.txt to the collection\n",
      "Added random_flight.txt to the collection\n",
      "Added spiral_dynamic.txt to the collection\n",
      "Added genetic_mutation.txt to the collection\n",
      "Added swarm_dynamic.txt to the collection\n",
      "Added local_random_walk to the collection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ollama  # Replace with the actual library you use for embeddings\n",
    "\n",
    "# Define the directory containing Python files\n",
    "operators_files_directory = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/operators_builder\" \n",
    "\n",
    "# Iterate through all items in the directory\n",
    "for d in os.listdir(operators_files_directory):\n",
    "    file_path = os.path.join(operators_files_directory, d)  # Full path to the file\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        try:\n",
    "            # Open and read the file\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            # Generate embeddings for the file content\n",
    "            response = ollama.embeddings(model=\"all-minilm:latest\", prompt=file_content)\n",
    "            embedding = response.get(\"embedding\")\n",
    "\n",
    "            # Add embedding to the collection if valid\n",
    "            if embedding:\n",
    "                operators_collection.add(\n",
    "                    ids=[d],\n",
    "                    embeddings=[embedding],\n",
    "                    documents=[file_content],\n",
    "                    metadatas=[{\"filename\": d}]\n",
    "                )\n",
    "                print(f\"Added {d} to the collection\")\n",
    "            else:\n",
    "                print(f\"Warning: Empty embedding generated for {d}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {d}: {e}\")\n",
    "    else:\n",
    "        # Skip if it's not a file\n",
    "        print(f\"Skipping {d}, not a file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feedback = [\"central_force_dynamic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['operators.txt', 'metaheuristic_template.txt']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Remember to write the operators\\' names, virables\\' names and selectors\\' names exactly as shown down below. For example, the operators\\' names are ALL ALWAYS written in lower case and with a \\'_\\' instead of a space between words.\\nSo write the parameters\\' exactly as shown down below. \\n\\nThese are the parameters to take, (REMEMBER that each operaotr must have its own selector, and that depending on the selected operator, YOU MUST ONLY USE USE ONE VARIABLE PER PARAMETER, DO NOT USE THE WHOLE ARRAY, and write the variable without an array format, but as a float or string format):\\nAlso consider, that if the dimension is bigger than 3, you must select selectors that have more space, such as \\'all\\'.\\n{\\n  \"random_search\": {  # operator\\n    { # parameters\\n      \"scale\": 1.0 or 0.01,\\n      \"distribution\": \"uniform\" or \"gaussian\" or \"levy\"\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"central_force_dynamic\": {  # operator\\n    { # parameters\\n      \"gravity\": 0.001,\\n      \"alpha\": 0.01,\\n      \"beta\": 1.5,\\n      \"dt\": 1.0\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"differential_mutation\": { # operator\\n    { # parameters\\n      \"expression\": \"rand\" or \"best\" or \"current\" or  \"current-to-best\" or \"rand-to-best\" or \"rand-to-best-and-current\",\\n      \"num_rands\": 1,\\n      \"factor\": 1.0\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"firefly_dynamic\": { # operator\\n    { # parameters\\n      \"distribution\": \"uniform\" or \"gaussian\" or \"levy\",\\n      \"alpha\": 1.0,\\n      \"beta\": 1.0,\\n      \"gamma\": 100.0\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"genetic_crossover\": { # operator: - If you decide to use the operator genetic_crossover, then you must use genetic_mutation too. And vice versa. \\n    { # parameters\\n      \"pairing\": \"rank\" or \"cost\" or \"random\" or\"tournament_2_100\",\\n      \"crossover\": \"single\" or \"two\" or \"uniform\" or \"blend\" or \"linear_0.5_0.5\",\\n      \"mating_pool_factor\": 0.4\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"genetic_mutation\": { # operator: - If you decide to use the operator genetic_crossover, then you must use genetic_mutation too. And vice versa. \\n    { # parameters\\n      \"scale\": 1.0,\\n      \"elite_rate\": 0.1,\\n      \"mutation_rate\": 0.25,\\n      \"distribution\": \"uniform\" or \"gaussian\" or \"levy\"\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"gravitational_search\": { # operator\\n    { # parameters\\n      \"gravity\": 1.0,\\n      \"alpha\": 0.02\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"random_flight\": { # operator\\n    { # parameters\\n      \"scale\": 1.0,\\n      \"distribution\": \"levy\" or \"uniform\" or\"gaussian\",\\n      \"beta\": 1.5\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"local_random_walk\": { # operator\\n    { # parameters\\n      \"probability\": 0.75,\\n      \"scale\": 1.0,\\n      \"distribution\": \"uniform\" or \"gaussian\" or \"levy\"\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"random_sample\": { # operator\\n    { }\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"spiral_dynamic\": { # operator\\n    { # parameters\\n      \"radius\": 0.9,\\n      \"angle\": 22.5,\\n      \"sigma\": 0.1\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  },\\n  \"swarm_dynamic\": { # operator\\n   { # parameters\\n      \"factor\": 0.7 or 1.0,\\n      \"self_conf\": 2.54,\\n      \"swarm_conf\": 2.56,\\n      \"version\": \"inertial\" or \"constriction\",\\n      \"distribution\": \"uniform\" or \"gaussian\" or \"levy\"\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n  }\\n}\\n',\n",
       "   '# This is the metaheuristic template:\\n\\nFormat your response exaclty as follows.  \\nDo not write anything before this format: \\n      \\n# Name: [Your chosen name for the metaheuristic]\\n# Code:\\nimport sys\\nfrom pathlib import Path\\nimport numpy as np\\nproject_dir = Path(__file__).resolve().parents[2] # Remember to write well this line: \\'project_dir = Path(__file__).resolve().parents[2]\\'\\nsys.path.insert(0, str(project_dir))\\nimport benchmark_func as bf\\nimport metaheuristic as mh\\n\\nfun = bf.{self.benchmark_function}({self.dimensions}) # This is the selected problem, the problem may vary depending on the case.\\nprob = fun.get_formatted_problem()\\n\\nheur = [\\n    (  # Search operator 1\\n        \\'[operator_name]\\',\\n        {\\n            \\'parameter1\\': value1,\\n            \\'parameter2\\': value2,\\n            more parameters as needed\\n        },\\n        \\'[selector_name]\\'\\n    ),\\n    (\\n        \\'[operator_name]\\',\\n        {\\n            \\'parameter1\\': value1,\\n            \\'parameter2\\': value2,\\n            ... more parameters as needed\\n        },\\n        \\'[selector_name]\\'\\n    )\\n]\\n\\nmet = mh.Metaheuristic(prob, heur, num_iterations=100)\\n#met.verbose = True # please comment this line\\n#met.run() # please comment this line\\n\\n#print(\\'x_best = {}, f_best = {}\\'.format(*met.get_solution()))\\n\\n# Initialise the fitness register\\nfitness = []\\n# Run the metaheuristic with the same problem 30 times\\nfor rep in range(30):\\n    met = mh.Metaheuristic(prob, heur, num_iterations=1000, num_agents=100)  \\n    met.reset_historicals()\\n    met.verbose = False\\n    met.run()\\n    #print(\\'rep = {}, x_best = {}, f_best = {}\\'.format(rep+1, *met.get_solution()))\\n    \\n    fitness.append(met.historical[\\'fitness\\'])\\n\\nfitness_array = np.array(fitness).T\\nfinal_fitness = np.array([x[-1] for x in fitness_array.T])\\nprint(\"final_fitness_array\", final_fitness)\\n\\n# Short explanation and justification:\\n# [Your explanation here, each line starting with \\'#\\']\\n']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'filename': 'operators.txt'},\n",
       "   {'filename': 'metaheuristic_template.txt'}]],\n",
       " 'distances': [[19.10363006591797, 20.78167724609375]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Probably not useful\n",
    "# all-minilm:latest\n",
    "output_metaheuristics = ollama.embeddings(\n",
    "        prompt=f\"Do not: {data_feedback}\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results_metaheuristics = python_collection.query (\n",
    "        query_embeddings=[output_metaheuristics[\"embedding\"]],\n",
    "        n_results=2\n",
    ")\n",
    "#data_metaheuristics = results_metaheuristics['documents'][0][0]\n",
    "results_metaheuristics\n",
    "#print(data_metaheuristics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment # 1\n",
    "#####  Trying to get ollama to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feedback = [\"central_force_dynamic\", 'differential_mutation',\n",
    "   \"random_search\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys/outputs-results/ollama_output_Rastrigin_15_20250108_165905/execution_iteration_0.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd()  # This assumes you're running the script from the repo root\n",
    "\n",
    "# Define the rest of the path relative to the repository root\n",
    "relative_path = Path(\"outputs-results/ollama_output_Rastrigin_15_20250108_165905/execution_iteration_0.py\")\n",
    "\n",
    "# Construct the full path\n",
    "execution_path = repo_root / relative_path\n",
    "try:\n",
    "    with open(execution_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()  # Reads the entire file as a string\n",
    "        print(content)  # Output the file content\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {execution_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed Path: /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/outputs-results/ollama_output_Rastrigin_15_20250108_165905/execution_iteration_0.py\n",
      "Does the file exist? True\n",
      "# Name: Hybrid Metaheuristic with Adaptive Strategies\n",
      "\n",
      "# Code:\n",
      "import sys\n",
      "from pathlib import Path\n",
      "import numpy as np\n",
      "project_dir = Path(__file__).resolve().parents[2]  # Remember to write well this line: 'project_dir = Path(__file__).resolve().parents[2]'\n",
      "sys.path.insert(0, str(project_dir))\n",
      "import benchmark_func as bf\n",
      "import metaheuristic as mh\n",
      "\n",
      "fun = bf.Rastrigin(15)  # This is the selected problem, the problem may vary depending on the case.\n",
      "prob = fun.get_formatted_problem()\n",
      "\n",
      "heur = [\n",
      "    (  # Search operator 1\n",
      "        'swarm_dynamic',\n",
      "        {\n",
      "            'factor': 0.7,\n",
      "            'self_conf': 2.54,\n",
      "            'swarm_conf': 2.56,\n",
      "            'version': 'inertial',\n",
      "            'distribution': 'uniform'\n",
      "        },\n",
      "        'probabilistic'\n",
      "    ),\n",
      "    (\n",
      "        'random_sample',\n",
      "        {},\n",
      "        'greedy'\n",
      "    )\n",
      "]\n",
      "\n",
      "met = mh.Metaheuristic(prob, heur, num_iterations=100)\n",
      "# met.verbose = True  # please comment this line\n",
      "# met.run()  # please comment this line\n",
      "\n",
      "# Initialise the fitness register\n",
      "fitness = []\n",
      "# Run the metaheuristic with the same problem 30 times\n",
      "for rep in range(30):\n",
      "    met = mh.Metaheuristic(prob, heur, num_iterations=1000, num_agents=100)\n",
      "    met.reset_historicals()\n",
      "    met.verbose = False\n",
      "    met.run()\n",
      "    # print('rep = {}, x_best = {}, f_best = {}'.format(rep+1, *met.get_solution()))\n",
      "    \n",
      "    fitness.append(met.historical['fitness'])\n",
      "\n",
      "fitness_array = np.array(fitness).T\n",
      "final_fitness = np.array([x[-1] for x in fitness_array.T])\n",
      "print(\"final_fitness_array\", final_fitness)\n",
      "\n",
      "# Short explanation and justification:\n",
      "# This hybrid metaheuristic combines the swarm dynamic operator with a random sample operator.\n",
      "# The swarm dynamic operator is used to explore the solution space effectively, while the random sample operator helps in escaping local minima.\n",
      "# The probabilistic selector allows the algorithm to balance exploration and exploitation dynamically.\n"
     ]
    }
   ],
   "source": [
    "# Correct base directory\n",
    "base_path = Path(\"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/outputs-results\")\n",
    "\n",
    "# Construct the full path\n",
    "relative_path = \"ollama_output_Rastrigin_15_20250108_165905/execution_iteration_0.py\"\n",
    "execution_path = base_path / relative_path\n",
    "\n",
    "print(\"Constructed Path:\", execution_path)\n",
    "print(\"Does the file exist?\", execution_path.exists())\n",
    "with execution_path.open('r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_operators_array = [\"random_search\", \"central_force_dynamic\", \"differential_mutation\", \"firefly_dynamic\", \"genetic_crossover\", \"genetic_mutation\", \"gravitational_search\", \"random_flight\", \"local_random_walk\", \"random_sample\", \"spiral_dynamic\", \"swarm_dynamic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_operators_array = ['central_force_dynamic', 'differential_mutation', 'firefly_dynamic', 'genetic_crossover', 'genetic_mutation', 'gravitational_search', 'random_flight', 'local_random_walk', 'spiral_dynamic']\n",
      "all_operators_array = ['central_force_dynamic', 'differential_mutation', 'firefly_dynamic', 'genetic_crossover', 'genetic_mutation', 'gravitational_search', 'random_flight', 'local_random_walk', 'spiral_dynamic']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# \n",
    "output = ollama.generate(\n",
    "    model=\"qwen2.5-coder:latest\",\n",
    "    prompt=f\"\"\"\n",
    "    Taking into account this metaheuristic created: {content} \n",
    "    Generate me an array such as called 'all_operators_array', such as: {all_operators_array}, \n",
    "    but without those metaheuristics encountered.\n",
    "    DO NOT USE ```python and do NOT use any markdown code or use the triple backticks  (```) anywhere in your response, and do not respond anything else.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(output['response'])\n",
    "answer = output['response']\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['differential_mutation.txt',\n",
       "   'central_force_dynamic.txt',\n",
       "   'random_search.txt']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['  \"differential_mutation\": { # operator\\n    { # parameters\\n      \"expression\": \"rand\" or \"best\" or \"current\" or  \"current-to-best\" or \"rand-to-best\" or \"rand-to-best-and-current\",\\n      \"num_rands\": 1,\\n      \"factor\": 1.0\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n}',\n",
       "   '\"central_force_dynamic\": {  # operator\\n    { # parameters\\n      \"gravity\": 0.001,\\n      \"alpha\": 0.01,\\n      \"beta\": 1.5,\\n      \"dt\": 1.0\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n}',\n",
       "   '\"random_search\": {  # operator\\n    { # parameters\\n      \"scale\": 1.0 or 0.01,\\n      \"distribution\": \"uniform\" or \"gaussian\" or \"levy\"\\n    },\\n    selector: \"greedy\" or \"all\" or\"metropolis\" or\"probabilistic\"\\n}']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'filename': 'differential_mutation.txt'},\n",
       "   {'filename': 'central_force_dynamic.txt'},\n",
       "   {'filename': 'random_search.txt'}]],\n",
       " 'distances': [[5.393641471862793, 5.624865531921387, 5.821882247924805]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Probably not useful\n",
    "# all-minilm:latest\n",
    "output_metaheuristics = ollama.embeddings(\n",
    "        prompt=f\"Create a metaheuristic with even two, three or more operators: {answer}\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results_metaheuristics = operators_collection.query (\n",
    "        query_embeddings=[output_metaheuristics[\"embedding\"]],\n",
    "        n_results=3\n",
    ")\n",
    "#data_metaheuristics = results_metaheuristics['documents'][0][0]\n",
    "results_metaheuristics\n",
    "#print(data_metaheuristics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Client.list of <ollama._client.Client object at 0x14720ed80>>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Name: EnhancedInertialSwarmOptimization\n",
      "\n",
      "# Code:\n",
      "import sys\n",
      "from pathlib import Path\n",
      "\n",
      "project_dir = Path(__file__).resolve().parents[2] # Remember to write well this line: 'project_dir = Path(__file__).resolve().parents[2]'\n",
      "sys.path.insert(0, str(project_dir))\n",
      "import benchmark_func as bf\n",
      "import metaheuristic as mh\n",
      "\n",
      "fun = bf.Rastrigin(5) # This is the selected problem, the problem may vary depending on the case.\n",
      "prob = fun.get_formatted_problem()\n",
      "\n",
      "heur = [\n",
      "    (  # Search operator 1\n",
      "        'swarm_dynamic',\n",
      "        {\n",
      "            'factor': 0.11779253652571474,\n",
      "            'self_conf': 2.951026835950703,\n",
      "            'swarm_conf': 2.7883600653077947,\n",
      "            'version': \"inertial\",\n",
      "            'distribution': \"uniform\"\n",
      "        },\n",
      "        'probabilistic'\n",
      "    ),\n",
      "    (\n",
      "        'local_random_walk',\n",
      "        {\n",
      "            'probability': 0.75,\n",
      "            'scale': 1.0,\n",
      "            'distribution': \"uniform\"\n",
      "        },\n",
      "        'probabilistic'\n",
      "    )\n",
      "]\n",
      "\n",
      "met = mh.Metaheuristic(prob, heur, num_iterations=1000)\n",
      "met.verbose = True\n",
      "met.run()\n",
      "\n",
      "print('x_best = {}, f_best = {}'.format(*met.get_solution()))\n",
      "\n",
      "# Initialise the fitness register\n",
      "fitness = []\n",
      "# Run the metaheuristic with the same problem 30 times\n",
      "for rep in range(30):\n",
      "    met = mh.Metaheuristic(prob, heur, num_iterations=1000, num_agents=5) # Please add more agents depending on the size of the dimension.\n",
      "    met.reset_historicals()\n",
      "    met.verbose = False\n",
      "    met.run()\n",
      "    print('rep = {}, x_best = {}, f_best = {}'.format(rep+1, *met.get_solution()))\n",
      "    \n",
      "    fitness.append(met.historical['fitness'])\n",
      "    \n",
      "# Short explanation and justification:\n",
      "# The enhanced performance of the metaheuristic is achieved by combining the 'swarm_dynamic' operator with a tuned set of parameters specific for the Rastrigin function. The 'local_random_walk' operator helps to escape local minima effectively, leading to better convergence and solution quality.\n",
      "\n",
      "# The 'radius', 'angle', and 'sigma' parameters in 'spiral_dynamic' were optimized separately and do not directly apply here, as the problem is a different benchmark (Rastrigin vs. spiral). Instead, the parameters from the original optimization are applied specifically to the 'swarm_dynamic' operator for optimal performance on this problem.\n"
     ]
    }
   ],
   "source": [
    "output = ollama.generate(\n",
    "   model = \"myqwen2.5:latest\",\n",
    "   prompt = f\"\"\"Using these parametes {data} and this metaheuristic data {data_metaheuristics}\n",
    "   , create another metaheuristic with a better performance, you must use the given parameters in {data} because\n",
    "   those are the ones that were genereted in an optimized function,\n",
    "   do not use markdown code anywhere in the project, take into account the problem fun = bf.Rastrigin(5).\n",
    "   \"\"\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
