{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "#### chromadb:\n",
    "#### ollama:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chroma_client.delete_collection(name=\"feedback_collection\") # Delete a collection and all associated embeddings, documents, and metadata. ⚠️ This is destructive and not reversible\n",
    "#chroma_client.delete_collection(name=\"python_collection\") # Delete a collection and all associated embeddings, documents, and metadata. ⚠️ This is destructive and not reversible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Feedback Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_collection = chroma_client.create_collection(name=\"feedback_collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_feedback_collection = chroma_client.create_collection(name=\"big_feedback_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filling Feedback Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "base_path = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys\"\n",
    "folder_name = \"ollama_output_Rastrigin_15_20250108_235511\"\n",
    "file_name = \"execution_optuna_result_0.txt\"\n",
    "metaheuristic_file  = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/outputs-results/ollama_output_Rastrigin(6)_20250107_144403/execution_optuna_result_0.txt\"\n",
    "\n",
    "# Construct the file path\n",
    "file_path = os.path.join(base_path, folder_name, file_name)\n",
    "with open(metaheuristic_file, 'r', encoding='utf-8') as file:\n",
    "    code_file = file.read()\n",
    "\n",
    "\n",
    "with open(metaheuristic_file, 'r', encoding='utf-8') as file:\n",
    "    metaheuristic_code_file = file.read()\n",
    "\n",
    "hyperparameters_pattern = r\"Mejores hiperparámetros encontrados:\\n({.*?})\"\n",
    "performance_pattern = r\"Mejor rendimiento encontrado:\\n([\\d.]+)\"\n",
    "\n",
    "hyperparameters_match = re.search(hyperparameters_pattern, code_file, re.DOTALL)\n",
    "hyperparameters_dict = eval(hyperparameters_match.group(1)) if hyperparameters_match else None\n",
    "\n",
    "performance_match = re.search(performance_pattern, code_file)\n",
    "performance_found = float(performance_match.group(1)) if performance_match else None\n",
    "\n",
    "if hyperparameters_dict:\n",
    "    radius = float(hyperparameters_dict.get('radius', 0))\n",
    "    angle = float(hyperparameters_dict.get('angle', 0))\n",
    "    sigma = float(hyperparameters_dict.get('sigma', 0))\n",
    "    factor = float(hyperparameters_dict.get('factor', 0))\n",
    "    self_conf = float(hyperparameters_dict.get('self_conf', 0))\n",
    "    swarm_conf = float(hyperparameters_dict.get('swarm_conf', 0))\n",
    "    version = hyperparameters_dict.get('version', '')\n",
    "    distribution = hyperparameters_dict.get('distribution', '')\n",
    "\n",
    "    \n",
    "    print(f\"radius: {radius}\")\n",
    "    print(f\"angle: {angle}\")\n",
    "    print(f\"sigma: {sigma}\")\n",
    "    print(f\"factor: {factor}\")\n",
    "    print(f\"self_conf: {self_conf}\")\n",
    "    print(f\"swarm_conf: {swarm_conf}\")\n",
    "    print(f\"version: {version}\")\n",
    "    print(f\"distribution: {distribution}\")\n",
    "\n",
    "print(f\"Performance found: {performance_found}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iteration = \"id_0\"\n",
    "parameters  = f\"\"\"radius\": {radius},\"angle\": {angle},\"sigma\": {sigma},\"factor\": {factor},\"self_conf\": {self_conf},\"swarm_conf\": {swarm_conf},\"version\": {version},\"distribution\": {distribution}, \"performance_found\": {performance_found}\"\"\"\n",
    "print(parameters)\n",
    "feedback_collection.add(\n",
    "    documents=[parameters],\n",
    "    metadatas={\"hnsw:space\": \"cosine\"},\n",
    "    ids=[\"id_parameters_0\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_collection.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "base_path = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys\"\n",
    "folder_name = \"ollama_output_Rastrigin_15_20250108_235511\"\n",
    "file_name = \"execution_optuna_result_0.txt\"\n",
    "metaheuristic_file  = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/outputs-results/ollama_output_Rastrigin(6)_20250107_144403/execution_optuna_result_1.txt\"\n",
    "\n",
    "# Construct the file path\n",
    "file_path = os.path.join(base_path, folder_name, file_name)\n",
    "with open(metaheuristic_file, 'r', encoding='utf-8') as file:\n",
    "    code_file = file.read()\n",
    "\n",
    "\n",
    "with open(metaheuristic_file, 'r', encoding='utf-8') as file:\n",
    "    metaheuristic_code_file = file.read()\n",
    "\n",
    "hyperparameters_pattern = r\"Mejores hiperparámetros encontrados:\\n({.*?})\"\n",
    "performance_pattern = r\"Mejor rendimiento encontrado:\\n([\\d.]+)\"\n",
    "\n",
    "hyperparameters_match = re.search(hyperparameters_pattern, code_file, re.DOTALL)\n",
    "hyperparameters_dict = eval(hyperparameters_match.group(1)) if hyperparameters_match else None\n",
    "\n",
    "performance_match = re.search(performance_pattern, code_file)\n",
    "performance_found = float(performance_match.group(1)) if performance_match else None\n",
    "\n",
    "if hyperparameters_dict:\n",
    "    radius = float(hyperparameters_dict.get('radius', 0))\n",
    "    angle = float(hyperparameters_dict.get('angle', 0))\n",
    "    sigma = float(hyperparameters_dict.get('sigma', 0))\n",
    "    factor = float(hyperparameters_dict.get('factor', 0))\n",
    "    self_conf = float(hyperparameters_dict.get('self_conf', 0))\n",
    "    swarm_conf = float(hyperparameters_dict.get('swarm_conf', 0))\n",
    "    version = hyperparameters_dict.get('version', '')\n",
    "    distribution = hyperparameters_dict.get('distribution', '')\n",
    "\n",
    "    \n",
    "    print(f\"radius: {radius}\")\n",
    "    print(f\"angle: {angle}\")\n",
    "    print(f\"sigma: {sigma}\")\n",
    "    print(f\"factor: {factor}\")\n",
    "    print(f\"self_conf: {self_conf}\")\n",
    "    print(f\"swarm_conf: {swarm_conf}\")\n",
    "    print(f\"version: {version}\")\n",
    "    print(f\"distribution: {distribution}\")\n",
    "\n",
    "print(f\"Performance found: {performance_found}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iteration = \"id_1\"\n",
    "parameters  = f\"\"\"radius\": {radius},\"angle\": {angle},\"sigma\": {sigma},\"factor\": {factor},\"self_conf\": {self_conf},\"swarm_conf\": {swarm_conf},\"version\": {version},\"distribution\": {distribution}, \"performance_found\": {performance_found}\"\"\"\n",
    "print(parameters)\n",
    "feedback_collection.add(\n",
    "    documents=[parameters],\n",
    "    metadatas={\"hnsw:space\": \"cosine\"},\n",
    "    ids=[\"id_parameters_1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "base_path = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys\"\n",
    "folder_name = \"ollama_output_Rastrigin_15_20250108_235511\"\n",
    "file_name = \"execution_optuna_result_0.txt\"\n",
    "\n",
    "\n",
    "# Construct the file path\n",
    "file_path = os.path.join(base_path, folder_name, file_name)\n",
    "\n",
    "file = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/outputs-results/ollama_output_Rastrigin(6)_20250107_144403/execution_optuna_result_2.txt\"\n",
    "with open(file, 'r', encoding='utf-8') as file:\n",
    "    code_file = file.read()\n",
    "\n",
    "hyperparameters_pattern = r\"Mejores hiperparámetros encontrados:\\n({.*?})\"\n",
    "performance_pattern = r\"Mejor rendimiento encontrado:\\n([\\d.]+)\"\n",
    "\n",
    "hyperparameters_match = re.search(hyperparameters_pattern, code_file, re.DOTALL)\n",
    "hyperparameters_dict = eval(hyperparameters_match.group(1)) if hyperparameters_match else None\n",
    "\n",
    "performance_match = re.search(performance_pattern, code_file)\n",
    "performance_found = float(performance_match.group(1)) if performance_match else None\n",
    "\n",
    "if hyperparameters_dict:\n",
    "    radius = float(hyperparameters_dict.get('radius', 0))\n",
    "    angle = float(hyperparameters_dict.get('angle', 0))\n",
    "    sigma = float(hyperparameters_dict.get('sigma', 0))\n",
    "    factor = float(hyperparameters_dict.get('factor', 0))\n",
    "    self_conf = float(hyperparameters_dict.get('self_conf', 0))\n",
    "    swarm_conf = float(hyperparameters_dict.get('swarm_conf', 0))\n",
    "    version = hyperparameters_dict.get('version', '')\n",
    "    distribution = hyperparameters_dict.get('distribution', '')\n",
    "\n",
    "    \n",
    "    print(f\"radius: {radius}\")\n",
    "    print(f\"angle: {angle}\")\n",
    "    print(f\"sigma: {sigma}\")\n",
    "    print(f\"factor: {factor}\")\n",
    "    print(f\"self_conf: {self_conf}\")\n",
    "    print(f\"swarm_conf: {swarm_conf}\")\n",
    "    print(f\"version: {version}\")\n",
    "    print(f\"distribution: {distribution}\")\n",
    "\n",
    "print(f\"Performance found: {performance_found}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iteration = \"id_2\"\n",
    "parameters  = f\"\"\"radius\": {radius},\"angle\": {angle},\"sigma\": {sigma},\"factor\": {factor},\"self_conf\": {self_conf},\"swarm_conf\": {swarm_conf},\"version\": {version},\"distribution\": {distribution}, \"performance_found\": {performance_found}\"\"\"\n",
    "print(parameters)\n",
    "feedback_collection.add(\n",
    "    documents=[parameters],\n",
    "    metadatas={\"hnsw:space\": \"cosine\"},\n",
    "    ids=[\"id_parameters_2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOT WORKING PROPERLY ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all-minilm:latest\n",
    "output = ollama.embeddings(\n",
    "        prompt=\"what is the smallest performance_found?\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results = feedback_collection.query (\n",
    "        query_embeddings=[output[\"embedding\"]],\n",
    "        n_results=3\n",
    ")\n",
    "data = results['documents'][0][0]\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment with big_feedback_collection\n",
    "##### Using cosine similarity, which is better than default (L2) for text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iteration = \"id_0\"\n",
    "parameters  = f\"\"\"random_search\", \"scale:\" {1.2},  \"distribution:\" {\"uniform\"}, \"performance_found\": {10.6784}\"\"\"\n",
    "print(parameters)\n",
    "big_feedback_collection.add(\n",
    "    documents=[parameters],\n",
    "    metadatas={\"hnsw:space\": \"cosine\"},\n",
    "    ids=[\"id_parameters_0\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iteration = \"id_1\"\n",
    "parameters  = f\"\"\"random_search\", \"scale:\" {5.2},  \"distribution:\" {\"gaussian\"}, \"performance_found\": {8.6784}\"\"\"\n",
    "print(parameters)\n",
    "big_feedback_collection.add(\n",
    "    documents=[parameters],\n",
    "    metadatas={\"hnsw:space\": \"cosine\"},\n",
    "    ids=[\"id_parameters_1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_iteration = \"id_2\"\n",
    "parameters  = f\"\"\"random_search\", \"scale:\" {9.2},  \"distribution:\" {\"gaussian\"}, \"performance_found\": {2.3332}\"\"\"\n",
    "print(parameters)\n",
    "big_feedback_collection.add(\n",
    "    documents=[parameters],\n",
    "    metadatas={\"hnsw:space\": \"cosine\"},\n",
    "    ids=[\"id_parameters_2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting ALL values from the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(big_feedback_collection)\n",
    "all_big_feedback_collection_documents = big_feedback_collection.get(\n",
    "    include=[\"documents\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_big_feedback_collection_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting a SINGLE value from the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(big_feedback_collection)\n",
    "single_value_big_feedback_collection_documents = big_feedback_collection.get(\n",
    "\tids=[\"id_parameters_1\"]\n",
    ")\n",
    "\n",
    "print(single_value_big_feedback_collection_documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOT working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # all-minilm:latest\n",
    "output = ollama.embeddings(\n",
    "        prompt=\"What is the smallest and best performance value?\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results = big_feedback_collection.query (\n",
    "        query_embeddings=[output[\"embedding\"]],\n",
    "        n_results=1\n",
    ")\n",
    "print(\"Output Embedding:\", output)\n",
    "print(\"Results:\", results)\n",
    "\n",
    "data = results['documents'] \n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NEW APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =\"qwen2.5-coder:latest\"\n",
    "output = ollama.generate(\n",
    "    model=\"qwen2.5-coder:latest\",\n",
    "    prompt=f\"\"\"\n",
    "    Give me the smallest performance_found encountered in here, give me the operators and parameters used: \n",
    "    {all_big_feedback_collection_documents}\n",
    "    \"\"\"\n",
    ")\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ollama.generate(\n",
    "    model=self.model,\n",
    "    prompt=f\"\"\"\n",
    "    {self.prompt} \n",
    "    DO NOT USE ```python and do NOT use any markdown code or use the triple backticks  (```) anywhere in your response.\n",
    "    From the data provided, extract operators while ensuring a variety of strategies. \n",
    "    Do not limit to just two or three specific types.\n",
    "    Strictly match the information below, without inventing or modifying any details:\n",
    "    Data, (DO NOT MODIFY ANY GIVEN OPERATORS, PARAMETERS, VARIABLES OR SELECTORS):\n",
    "    {data}\n",
    "    Use the following template for your response:\n",
    "    {data_template}\n",
    "    If you encounter an error, address it as follows: {self.file_result_error}.\n",
    "    \"\"\"\n",
    ")\n",
    "output_response = self.execute_generated_code(output['response'], output_folder, number_iteration, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all-minilm:latest\n",
    "output = ollama.embeddings(\n",
    "        prompt=\"What is the smallest and best performance value?\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results = big_feedback_collection.query (\n",
    "        query_embeddings=[output[\"embedding\"]],\n",
    "        n_results=1\n",
    ")\n",
    "print(\"Output Embedding:\", output)\n",
    "print(\"Results:\", results)\n",
    "\n",
    "data = results['documents'] \n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Metaheuristic Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_collection = chroma_client.create_collection(name=\"python_collection\")\n",
    "# /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/operators_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama  # Replace with the actual library you use for embeddings\n",
    "\n",
    "# Define the directory containing Python files\n",
    "python_files_directory = '/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/metaheuristic_builder'\n",
    "\n",
    "# Iterate through all items in the directory\n",
    "for d in os.listdir(python_files_directory):\n",
    "    file_path = os.path.join(python_files_directory, d)  # Full path to the file\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        try:\n",
    "            # Open and read the file\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            # Generate embeddings for the file content\n",
    "            response = ollama.embeddings(model=\"all-minilm:latest\", prompt=file_content)\n",
    "            embedding = response.get(\"embedding\")\n",
    "\n",
    "            # Add embedding to the collection if valid\n",
    "            if embedding:\n",
    "                python_collection.add(\n",
    "                    ids=[d],\n",
    "                    embeddings=[embedding],\n",
    "                    documents=[file_content],\n",
    "                    metadatas=[{\"filename\": d}]\n",
    "                )\n",
    "                print(f\"Added {d} to the collection\")\n",
    "            else:\n",
    "                print(f\"Warning: Empty embedding generated for {d}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {d}: {e}\")\n",
    "    else:\n",
    "        # Skip if it's not a file\n",
    "        print(f\"Skipping {d}, not a file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_collection.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Operators Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators_collection = chroma_client.create_collection(name=\"operators_collection\")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama  # Replace with the actual library you use for embeddings\n",
    "\n",
    "# Define the directory containing Python files\n",
    "operators_files_directory = \"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/operators_builder\" \n",
    "\n",
    "# Iterate through all items in the directory\n",
    "for d in os.listdir(operators_files_directory):\n",
    "    file_path = os.path.join(operators_files_directory, d)  # Full path to the file\n",
    "    if os.path.isfile(file_path):  # Check if it's a file\n",
    "        try:\n",
    "            # Open and read the file\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            # Generate embeddings for the file content\n",
    "            response = ollama.embeddings(model=\"all-minilm:latest\", prompt=file_content)\n",
    "            embedding = response.get(\"embedding\")\n",
    "\n",
    "            # Add embedding to the collection if valid\n",
    "            if embedding:\n",
    "                operators_collection.add(\n",
    "                    ids=[d],\n",
    "                    embeddings=[embedding],\n",
    "                    documents=[file_content],\n",
    "                    metadatas=[{\"filename\": d}]\n",
    "                )\n",
    "                print(f\"Added {d} to the collection\")\n",
    "            else:\n",
    "                print(f\"Warning: Empty embedding generated for {d}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {d}: {e}\")\n",
    "    else:\n",
    "        # Skip if it's not a file\n",
    "        print(f\"Skipping {d}, not a file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feedback = [\"central_force_dynamic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Probably not useful\n",
    "# all-minilm:latest\n",
    "output_metaheuristics = ollama.embeddings(\n",
    "        prompt=f\"Do not: {data_feedback}\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results_metaheuristics = python_collection.query (\n",
    "        query_embeddings=[output_metaheuristics[\"embedding\"]],\n",
    "        n_results=2\n",
    ")\n",
    "#data_metaheuristics = results_metaheuristics['documents'][0][0]\n",
    "results_metaheuristics\n",
    "#print(data_metaheuristics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experiment # 1\n",
    "#####  Trying to get ollama to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feedback = [\"central_force_dynamic\", 'differential_mutation',\n",
    "   \"random_search\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd()  # This assumes you're running the script from the repo root\n",
    "\n",
    "# Define the rest of the path relative to the repository root\n",
    "relative_path = Path(\"outputs-results/ollama_output_Rastrigin_15_20250108_165905/execution_iteration_0.py\")\n",
    "\n",
    "# Construct the full path\n",
    "execution_path = repo_root / relative_path\n",
    "try:\n",
    "    with open(execution_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()  # Reads the entire file as a string\n",
    "        print(content)  # Output the file content\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {execution_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct base directory\n",
    "base_path = Path(\"/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/outputs-results\")\n",
    "\n",
    "# Construct the full path\n",
    "relative_path = \"ollama_output_Rastrigin_15_20250108_165905/execution_iteration_0.py\"\n",
    "execution_path = base_path / relative_path\n",
    "\n",
    "print(\"Constructed Path:\", execution_path)\n",
    "print(\"Does the file exist?\", execution_path.exists())\n",
    "with execution_path.open('r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_operators_array = [\"random_search\", \"central_force_dynamic\", \"differential_mutation\", \"firefly_dynamic\", \"genetic_crossover\", \"genetic_mutation\", \"gravitational_search\", \"random_flight\", \"local_random_walk\", \"random_sample\", \"spiral_dynamic\", \"swarm_dynamic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "output = ollama.generate(\n",
    "    model=\"qwen2.5-coder:latest\",\n",
    "    prompt=f\"\"\"\n",
    "    Taking into account this metaheuristic created: {content} \n",
    "    Generate me an array such as called 'all_operators_array', such as: {all_operators_array}, \n",
    "    but without those metaheuristics encountered.\n",
    "    DO NOT USE ```python and do NOT use any markdown code or use the triple backticks  (```) anywhere in your response, and do not respond anything else.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(output['response'])\n",
    "answer = output['response']\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Probably not useful\n",
    "# all-minilm:latest\n",
    "output_metaheuristics = ollama.embeddings(\n",
    "        prompt=f\"Create a metaheuristic with even two, three or more operators: {answer}\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results_metaheuristics = operators_collection.query (\n",
    "        query_embeddings=[output_metaheuristics[\"embedding\"]],\n",
    "        n_results=3\n",
    ")\n",
    "#data_metaheuristics = results_metaheuristics['documents'][0][0]\n",
    "results_metaheuristics\n",
    "#print(data_metaheuristics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ollama.generate(\n",
    "   model = \"myqwen2.5:latest\",\n",
    "   prompt = f\"\"\"Using these parametes {data} and this metaheuristic data {data_metaheuristics}\n",
    "   , create another metaheuristic with a better performance, you must use the given parameters in {data} because\n",
    "   those are the ones that were genereted in an optimized function,\n",
    "   do not use markdown code anywhere in the project, take into account the problem fun = bf.Rastrigin(5).\n",
    "   \"\"\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Things to try: \n",
    "- Generating Better Vector Embeddings with Gemini Pro\n",
    "- metadatas={\"hnsw:space\": \"cosine\"} (better for text embeddings)\n",
    "- actual feedback:\n",
    "\n",
    "\n",
    "\n",
    "- Extra: How to Use CUDA and Multiprocessing to Add Records/Embeddings Faster in ChromaDB\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First change \n",
    "- metadatas={\"hnsw:space\": \"cosine\"} (better for text embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb \n",
    "import ollama\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=\"vectordb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators_collection = chroma_client.create_collection(name=\"operators_collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama  # Replace with the actual library you use for embeddings\n",
    "import json\n",
    "\n",
    "# Define the directory containing Python files\n",
    "python_files_directory = '/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/ioh_metaheuristic_builder/operators.txt'\n",
    "# Open and read the file\n",
    "with open(python_files_directory, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    " # Split the content into blocks by double newlines\n",
    "blocks = content.split(\"\\n\\n\")\n",
    "\n",
    "# Clean up and store blocks\n",
    "documents = [block.strip() for block in blocks if block.strip()]\n",
    "\n",
    "# Print results for verification\n",
    "for i, block in enumerate(documents, start=1):\n",
    "    print(f\"{'-' * 40}\")\n",
    "    response = ollama.embeddings(model=\"all-minilm:latest\", prompt=block)\n",
    "    embedding = response.get(\"embedding\")\n",
    "\n",
    "    # Add embedding to the collection if valid\n",
    "    if embedding:\n",
    "        operators_collection.add(\n",
    "            ids=[f\"operator: {i}\"],\n",
    "            embeddings=[embedding],\n",
    "            documents=[block],\n",
    "            metadatas=[{\"hnsw:space\": \"cosine\"}]\n",
    "        )\n",
    "        print(f\"Added {i} to the collection\")\n",
    "    else:\n",
    "        print(f\"Warning: Empty embedding generated for {i}\")\n",
    "\n",
    "# Save blocks into a new file\n",
    "with open(\"parsed_operators.txt\", \"w\") as output_file:\n",
    "    for block in documents:\n",
    "        output_file.write(block + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metaheuristics = ollama.embeddings(\n",
    "        prompt=f\"Give me an operator about dynamics\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results_metaheuristics = operators_collection.query (\n",
    "        query_embeddings=[output_metaheuristics[\"embedding\"]],\n",
    "        n_results=4\n",
    ")\n",
    "#data_metaheuristics = results_metaheuristics['documents'][0][0]\n",
    "results_metaheuristics\n",
    "#print(data_metaheuristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_collection = chroma_client.create_collection(name=\"test_collection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama  # Replace with the actual library you use for embeddings\n",
    "import json\n",
    "\n",
    "# Define the directory containing Python files\n",
    "test_files_directory = '/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys/test.txt'\n",
    "# Open and read the file\n",
    "with open(test_files_directory, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    " # Split the content into blocks by double newlines\n",
    "blocks = content.split(\"\\n\\n\")\n",
    "\n",
    "# Clean up and store blocks\n",
    "documents = [block.strip() for block in blocks if block.strip()]\n",
    "\n",
    "# Print results for verification\n",
    "for i, block in enumerate(documents, start=1):\n",
    "    print(f\"{'-' * 40}\")\n",
    "    response = ollama.embeddings(model=\"all-minilm:latest\", prompt=block)\n",
    "    embedding = response.get(\"embedding\")\n",
    "\n",
    "    # Add embedding to the collection if valid\n",
    "    if embedding:\n",
    "        test_collection.add(\n",
    "            ids=[f\"operator: {i}\"],\n",
    "            embeddings=[embedding],\n",
    "            documents=[block],\n",
    "            metadatas=[{\"hnsw:space\": \"cosine\"}]\n",
    "        )\n",
    "        print(f\"Added {i} to the collection\")\n",
    "    else:\n",
    "        print(f\"Warning: Empty embedding generated for {i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_metaheuristics = ollama.embeddings(\n",
    "        prompt=f\"Give me the result with the smallest performance\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results_metaheuristics = test_collection.query (\n",
    "        query_embeddings=[output_metaheuristics[\"embedding\"]],\n",
    "        n_results=3\n",
    ")\n",
    "#data_metaheuristics = results_metaheuristics['documents'][0][0]\n",
    "results_metaheuristics\n",
    "#print(data_metaheuristics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (0.5.20)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (0.115.5)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (3.7.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (4.67.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (0.13.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
      "Requirement already satisfied: anyio in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (5.28.3)\n",
      "Requirement already satisfied: sympy in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.49b2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.48.0)\n",
      "Requirement already satisfied: tqdm in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb\n",
    "\n",
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEY: AIzaSyClnhvj-6aQdDS2qcheEoep2SiCUXvQz-I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding ollama phi4\n",
    "- Adding Gemini pro (for the embedding model)\n",
    "\n",
    "-> By default, Chroma converts the text into the embeddings using all-MiniLM-L6-v2, but you can modify the collection to use another embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_ef  = embedding_functions.GoogleGenerativeAiEmbeddingFunction(api_key=\"AIzaSyClnhvj-6aQdDS2qcheEoep2SiCUXvQz-I\")\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name=\"my_test_collection_2\", embedding_function=google_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: operator: 1\n",
      "Insert of existing embedding ID: operator: 1\n",
      "Add of existing embedding ID: operator: 2\n",
      "Insert of existing embedding ID: operator: 2\n",
      "Add of existing embedding ID: operator: 3\n",
      "Insert of existing embedding ID: operator: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Added 1 to the collection\n",
      "----------------------------------------\n",
      "Added 2 to the collection\n",
      "----------------------------------------\n",
      "Added 3 to the collection\n",
      "----------------------------------------\n",
      "Added 4 to the collection\n",
      "----------------------------------------\n",
      "Added 5 to the collection\n",
      "----------------------------------------\n",
      "Added 6 to the collection\n",
      "----------------------------------------\n",
      "Added 7 to the collection\n",
      "----------------------------------------\n",
      "Added 8 to the collection\n",
      "----------------------------------------\n",
      "Added 9 to the collection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ollama  # Replace with the actual library you use for embeddings\n",
    "import json\n",
    "\n",
    "# Define the directory containing Python files\n",
    "test_files_directory = '/Users/valeriaenriquezlimon/Documents/meta-h-generator/llm-metaheuristics/experiments-custumhys/test.txt'\n",
    "# Open and read the file\n",
    "with open(test_files_directory, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    " # Split the content into blocks by double newlines\n",
    "blocks = content.split(\"\\n\\n\")\n",
    "\n",
    "# Clean up and store blocks\n",
    "documents = [block.strip() for block in blocks if block.strip()]\n",
    "\n",
    "# Print results for verification\n",
    "for i, block in enumerate(documents, start=1):\n",
    "    print(f\"{'-' * 40}\")\n",
    "    response = ollama.embeddings(model=\"all-minilm:latest\", prompt=block)\n",
    "    embedding = response.get(\"embedding\")\n",
    "\n",
    "    # Add embedding to the collection if valid\n",
    "    if embedding:\n",
    "        collection.add(\n",
    "            ids=[f\"operator: {i}\"],\n",
    "            embeddings=[embedding],\n",
    "            documents=[block],\n",
    "            metadatas=[{\"hnsw:space\": \"cosine\"}]\n",
    "        )\n",
    "        print(f\"Added {i} to the collection\")\n",
    "    else:\n",
    "        print(f\"Warning: Empty embedding generated for {i}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['operator: 9', 'operator: 2', 'operator: 8']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['\"random_search\", \"scale:\" {10.4},  \"distribution:\" {\"gaussian\"}, \"performance_found\": {0.5678}',\n",
       "   '\"random_search\", \"scale:\" {9.2},  \"distribution:\" {\"gaussian\"}, \"performance_found\": {2.3332}',\n",
       "   '\"random_search\", \"scale:\" {10.4},  \"distribution:\" {\"gaussian\"}, \"performance_found\": {4.5678}']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'hnsw:space': 'cosine'},\n",
       "   {'hnsw:space': 'cosine'},\n",
       "   {'hnsw:space': 'cosine'}]],\n",
       " 'distances': [[35.59996032714844, 35.629051208496094, 35.78778839111328]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_metaheuristics = ollama.embeddings(\n",
    "        prompt=f\"Give me the result with the smallest performance\",\n",
    "        model=\"all-minilm:latest\",\n",
    ")\n",
    "results_metaheuristics = collection.query (\n",
    "        query_embeddings=[output_metaheuristics[\"embedding\"]],\n",
    "        n_results=3\n",
    ")\n",
    "#data_metaheuristics = results_metaheuristics['documents'][0][0]\n",
    "results_metaheuristics\n",
    "#print(data_metaheuristics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are much better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
